# Monitor de VigilÃ¢ncia EpidemiolÃ³gica SRAG com Agentes de IA

> **SoluÃ§Ã£o de InteligÃªncia HÃ­brida:** Pipeline ETL automatizado, orquestraÃ§Ã£o cognitiva com LangGraph e anÃ¡lise de dados multimodal para vigilÃ¢ncia da SÃ­ndrome RespiratÃ³ria Aguda Grave (SRAG).

Este projeto implementa um sistema que transforma dados brutos do OpenDataSUS em inteligÃªncia acionÃ¡vel. Ele combina engenharia de dados, agentes de IA autÃ´nomos e uma interface interativa para apoiar a tomada de decisÃ£o em saÃºde pÃºblica.

---

## ğŸ¯ VisÃ£o Geral do Projeto

O monitoramento de surtos epidÃªmicos exige velocidade e precisÃ£o. Este projeto resolve o desafio de integrar dados histÃ³ricos (estruturados) com o contexto atual de notÃ­cias (nÃ£o estruturados) atravÃ©s de uma arquitetura em 4 camadas:

1. **Camada de Dados (ETL Automatizado):** Pipeline que baixa, sanitiza e padroniza dados do OpenDataSUS, criando um *Data Warehouse* local otimizado (SQLite).
2. **Camada Cognitiva (Agente ReAct):** Um agente autÃ´nomo baseado em LangGraph que "pensa" e decide quais ferramentas usar para responder a perguntas complexas.
3. **Camada de Ferramentas (Habilidades):**
* **SQL Tool:** Capacidade de executar consultas analÃ­ticas complexas no banco de dados.
* **RAG HÃ­brido:** Sistema de busca que combina vetores (FAISS) e palavras-chave (BM25) para encontrar notÃ­cias relevantes na web via Tavily API.
4. **Camada de ApresentaÃ§Ã£o:** Interface Streamlit que orquestra todo o fluxo e apresenta relatÃ³rios tÃ©cnicos e dashboards visuais.

---

## ğŸš€ Funcionalidades Principais

* **Arquitetura "Token-Efficient":** EstratÃ©gia de engenharia de prompt e schema de banco de dados otimizado.
* **OrquestraÃ§Ã£o (Loop):** Uso do LangGraph para permitir que o agente refine suas buscas e corrija erros autonomamente antes de gerar a resposta final.
* **VisualizaÃ§Ã£o:** GeraÃ§Ã£o de grÃ¡ficos de tendÃªncia (Matplotlib/Seaborn) integrados ao relatÃ³rio.

---

## ğŸ—ï¸ Arquitetura da SoluÃ§Ã£o

A soluÃ§Ã£o segue uma arquitetura modular conforme descrito a seguir:

![Diagrama Conceitual](docs/diagrama_conceitual.png)

### 1. Pipeline de Dados (ETL)

Localizado em `src/etl/`. ResponsÃ¡vel por:

* **Downloader:** Baixa arquivos Parquet/CSV de mÃºltiplas fontes (anos 2023-2025).
* **Processor:** Aplica regras de negÃ³cio, traduz cÃ³digos (ex: `1` -> `Cura`) e filtra colunas para otimizar o contexto da IA.
* **Loader:** Persiste os dados limpos em um banco SQLite (`data/srag_data.db`).

### 2. NÃºcleo de InteligÃªncia (Brain)

Localizado em `src/intelligence/`. Implementa:

* **Graph:** O grafo de estado que define o fluxo de pensamento do agente (RaciocÃ­nio -> AÃ§Ã£o -> ObservaÃ§Ã£o).
* **Tools:** Ferramentas customizadas que dÃ£o "superpoderes" ao modelo de linguagem.

### 3. VisualizaÃ§Ã£o e Interface

* **Plotter:** Gera imagens estÃ¡ticas para anÃ¡lise visual (`src/visualization/`).
* **App:** O ponto de entrada do usuÃ¡rio (`app.py`), construÃ­do em Streamlit.

---

## ğŸ› ï¸ Tech Stack

| Componente | Tecnologia | PropÃ³sito |
| --- | --- | --- |
| **OrquestraÃ§Ã£o de Agente** | **LangChain & LangGraph** | Gerenciamento de estado, memÃ³ria e fluxo cÃ­clico de decisÃ£o. |
| **LLM (CÃ©rebro)** | **OpenAI GPT-4o** | Modelo principal para raciocÃ­nio estratÃ©gico e sÃ­ntese de relatÃ³rio. |
| **LLM (Ferramentas)** | **OpenAI GPT-4o-mini** | Modelo otimizado para tarefas especÃ­ficas (geraÃ§Ã£o de SQL) visando economia. |
| **Banco de Dados** | **SQLite** | Armazenamento local leve e performÃ¡tico para dados analÃ­ticos. |
| **Busca & RAG** | **Tavily API & FAISS** | RecuperaÃ§Ã£o de informaÃ§Ãµes em tempo real na web e busca semÃ¢ntica. |
| **Engenharia de Dados** | **Pandas & PyArrow** | ManipulaÃ§Ã£o eficiente de grandes volumes de dados (ETL). |
| **Interface** | **Streamlit** | Frontend interativo para acionamento e visualizaÃ§Ã£o. |

---

## ğŸ“‚ Estrutura do Projeto

```text
.
â”œâ”€â”€ .env.example              # Template de variÃ¡veis de ambiente
â”œâ”€â”€ .gitignore                # Arquivos ignorados pelo Git
â”œâ”€â”€ app.py                    # AplicaÃ§Ã£o Principal (Frontend)
â”œâ”€â”€ requirements.txt          # DependÃªncias do projeto
â”œâ”€â”€ README.md                 # DocumentaÃ§Ã£o
â”‚
â”œâ”€â”€ config/                   # ConfiguraÃ§Ãµes Globais
â”‚   â”œâ”€â”€ settings.py           # Gerenciamento de caminhos e chaves
â”‚   â””â”€â”€ prompts.py            # Engenharia de Prompts (System Messages)
â”‚
â”œâ”€â”€ data/                     # Armazenamento Local
â”‚   â”œâ”€â”€ srag_data.db          # Banco de dados SQLite gerado
â”‚   â””â”€â”€ dicionario_dados.json # Metadados para traduÃ§Ã£o de colunas
â”‚
â”œâ”€â”€ img/                      # SaÃ­da de GrÃ¡ficos Gerados
â”‚
â””â”€â”€ src/                      # CÃ³digo Fonte Modular
    â”œâ”€â”€ etl/                  # Camada de Engenharia de Dados
    â”‚   â”œâ”€â”€ downloader.py     # Coleta de dados
    â”‚   â”œâ”€â”€ processor.py      # Limpeza e transformaÃ§Ã£o
    â”‚   â””â”€â”€ pipeline.py       # Orquestrador do ETL
    â”‚
    â”œâ”€â”€ intelligence/         # Camada de IA (Agentes)
    â”‚   â”œâ”€â”€ graph.py          # Grafo de decisÃ£o (LangGraph)
    â”‚   â”œâ”€â”€ tools.py          # Ferramentas (SQL, RAG)
    â”‚   â””â”€â”€ state.py          # DefiniÃ§Ã£o de estado do agente
    â”‚
    â””â”€â”€ visualization/        # Camada Visual
        â””â”€â”€ plotter.py        # GeraÃ§Ã£o de grÃ¡ficos estatÃ­sticos

```

---

## ğŸš€ Como Executar

### PrÃ©-requisitos

* Python 3.10 ou superior
* Conta na OpenAI (API Key)
* Conta na Tavily (API Key)

### Passo a Passo

1. **Clone o repositÃ³rio:**
```bash
git clone https://github.com/jorgefigueirajr/monitor-srag-ai.git
cd monitor-srag-ai

```


2. **Crie e ative o ambiente virtual:**
```bash
# Windows
python -m venv venv
.\venv\Scripts\activate

# Linux/Mac
python3 -m venv venv
source venv/bin/activate

```


3. **Instale as dependÃªncias:**
```bash
pip install -r requirements.txt

```


4. **Configure as Chaves de API:**
* Renomeie o arquivo `.env.example` para `.env`.
* Insira suas chaves no arquivo `.env`:
```ini
OPENAI_API_KEY="sk-..."
TAVILY_API_KEY="tvly-..."

```




5. **Execute a AplicaÃ§Ã£o:**
```bash
streamlit run app.py

```



Acesse a URL exibida no terminal (geralmente `http://localhost:8501`).

---

## ğŸ§  Como Funciona a AnÃ¡lise (Sob o CapÃ´)

Ao clicar em **"Iniciar AnÃ¡lise Completa"**, o sistema executa:

1. **SincronizaÃ§Ã£o de Dados:** O `pipeline.py` verifica se o banco de dados estÃ¡ atualizado. Se nÃ£o, baixa os dados mais recentes do governo.
2. **VisualizaÃ§Ã£o:** O `plotter.py` gera grÃ¡ficos atualizados da situaÃ§Ã£o epidemiolÃ³gica.
3. **InjeÃ§Ã£o de Contexto:** O sistema lÃª a data mais recente disponÃ­vel no banco e injeta no prompt do agente (evitando que ele "pense" que hoje Ã© outra data).
4. **Ciclo de InteligÃªncia:**
* O Agente recebe a missÃ£o.
* Decide consultar o banco via SQL para obter nÃºmeros exatos (Casos, Ã“bitos, UTI).
* Decide pesquisar na web notÃ­cias sobre surtos recentes para explicar os nÃºmeros.
* Cruza as informaÃ§Ãµes e escreve o relatÃ³rio final.
